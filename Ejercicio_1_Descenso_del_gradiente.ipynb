{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMmmcl56kaalH0QhweTTT9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EstebanmAcero/Neural_nets/blob/main/Ejercicio_1_Descenso_del_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Luis Esteban Molina Acero 201910203**\n",
        "#**Manuel Velez PhD.**\n"
      ],
      "metadata": {
        "id": "1l1VcW_Svtul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descenso del gradiente"
      ],
      "metadata": {
        "id": "2L-rE4Ff1lfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "13FuuprD4hnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# elegir una funcion para optimizar\n",
        "\n",
        "fun = lambda th : np.sin(1/2*x ** 2 -1 / 4 * y** 2+3)* np.cos(2*x + 1 - np.e**y)\n",
        "# le pasamos un vector de parametros\n",
        "func = lambda th : np.sin(1/2*th[0] ** 2 -1 / 4 * th[1]** 2+3)* np.cos(2*th[0] + 1 - np.e**th[1])\n",
        "func ([5, 3])\n",
        "\n"
      ],
      "metadata": {
        "id": "CI5Eb7yg4iQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate\n",
        "# Vamos a generar un vector de parametros para X y para Y\n",
        "# Luego lo representamos en una grafica\n",
        "\n",
        "res = 100 # resolution\n",
        "_X = np.linspace (-2,2, res) # un vector que vaya desde -2 hasta 2 que genere 100 valores\n",
        "_Y = np.linspace (-2,2, res)\n",
        "print(_X)\n",
        "\n",
        "func([5, 3])"
      ],
      "metadata": {
        "id": "3o7TUHTl6Ger"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lo que queremos es que para cada valor de x y y se genere un valor\n",
        "_Z = np.zeros ((res, res)) # estamos elaborando una matriz de 100 por 100\n",
        "\n",
        "# Vamos iterar para recorrer los elementos de _X\n",
        "# para cada valor devuelve su indice y su valor\n",
        "\n",
        "for ix, x in enumerate (_X):\n",
        "  for iy, y in enumerate (_Y):\n",
        "    # vamos a guardar los valores de la funcion\n",
        "\n",
        "      _Z[iy, ix] = func([x, y]) # esto se pasa como un vector de parametros\n",
        "\n",
        "# para visualizar _Z vamos a utilizar\n",
        "plt.contour?\n",
        "plt.contour(_X,_Y,_Z,100)\n",
        "plt.contourf(_X,_Y,_Z,100)\n",
        "plt.colorbar() # esto se utiliza para ver que representa cada color\n",
        "\n",
        "Theta = np.random.rand(2)* 4-2\n",
        "\n",
        "\n",
        "plt.plot(Theta[0], Theta[1], \"o\", c= \"red\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gHREKAx_6zvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Herramienta de las derivadas parciales\n",
        "\n",
        "h = 0.001\n",
        "_T = np.copy(Theta)\n",
        "\n",
        "grad = np.zeros(2)\n",
        "\n",
        "#Agregar el learning rate\n",
        "lr  = 0.001\n",
        "\n",
        "plt.contour(_X,_Y,_Z,100)\n",
        "plt.contourf(_X,_Y,_Z,100)\n",
        "plt.colorbar() # esto se utiliza para ver que representa cada color\n",
        "plt.plot(Theta[0], Theta[1], \"o\", c= \"white\")\n",
        "\n",
        "for _ in range (10000):\n",
        "    for it, th in enumerate (Theta):\n",
        "\n",
        "      #Agregarle el valor original\n",
        "\n",
        "        _T = np.copy(Theta)\n",
        "        # calcular las peque√±as diferecias\n",
        "        _T[it]= _T [it]+ h\n",
        "\n",
        "        deriv = (func(_T) - func(Theta))/h\n",
        "        grad [it]= deriv\n",
        "    Theta = Theta +lr* grad\n",
        "\n",
        "   # print(func(Theta))\n",
        "\n",
        "    # cuando el numero de iteraciones se igual a cinco\n",
        "\n",
        "    # _\n",
        "\n",
        "    if ( _%100 == 0):\n",
        "      # Aca vamos a dibujar un punto por cada iteracion\n",
        "      plt.plot(Theta[0], Theta[1], \"o\", c= \"red\")\n",
        "\n",
        "\n",
        "plt.plot(Theta[0], Theta[1], \"o\", c= \"green\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XtvnWqwS9UJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}